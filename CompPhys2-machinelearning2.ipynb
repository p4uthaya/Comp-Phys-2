{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of phases of matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Machine Learning Phases of Matter*, Juan Carrasquilla and Roger Melko, Nature Physics 13, 431 (2017)\n",
    "\n",
    "(https://arxiv.org/abs/1605.01735)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_images(filename,L):\n",
    "    \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\"\"\"\n",
    "    print ('Extracting', filename)\n",
    "    data=np.loadtxt(filename,dtype='uint8')\n",
    "    dim=data.shape[0]\n",
    "    data=data.reshape(dim,L,L,1) \n",
    "    print(data.shape)\n",
    "    return data\n",
    "\n",
    "def extract_labels(nlabels,filename):\n",
    "    \"\"\"Extract the labels into a 1D uint8 numpy array [index].\"\"\"\n",
    "    print('Extracting', filename)\n",
    "\n",
    "    labels=np.loadtxt(filename,dtype='uint8')\n",
    "    print(\"LABELS\")\n",
    "    print(labels.shape)\n",
    "    return labels\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, images, labels, fake_data=False):\n",
    "        if fake_data:\n",
    "            self._num_examples = 10000\n",
    "        else:\n",
    "            assert images.shape[0] == labels.shape[0], (\n",
    "                \"images.shape: %s labels.shape: %s\" % (images.shape,\n",
    "                                                       labels.shape))\n",
    "            self._num_examples = images.shape[0]\n",
    "            # Convert shape from [num examples, rows, columns, depth]\n",
    "            # to [num examples, rows*columns] (assuming depth == 1)\n",
    "            assert images.shape[3] == 1\n",
    "            images = images.reshape(images.shape[0],\n",
    "                                    images.shape[1] * images.shape[2])\n",
    "            # Convert from [0, 255] -> [0.0, 1.0].\n",
    "            images = images.astype(np.float32)\n",
    "            # images = numpy.multiply(images, 1.0 / 255.0) # commented since it is ising variables\n",
    "            images = np.multiply(images, 1.0 ) # multiply by one, instead\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size, fake_data=False):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        if fake_data:\n",
    "            fake_image = [1.0 for _ in xrange(400)]\n",
    "            fake_label = 0\n",
    "            return [fake_image for _ in xrange(batch_size)], [\n",
    "                fake_label for _ in xrange(batch_size)]\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self._images[start:end], self._labels[start:end]\n",
    "\n",
    "def read_data_sets(nlabels,L):\n",
    "    class DataSets(object):\n",
    "        pass\n",
    "    data_sets = DataSets()\n",
    "    TRAIN_IMAGES = 'Xtrain.txt'\n",
    "    TRAIN_LABELS = 'ytrain.txt'\n",
    "    TEST_IMAGES = 'Xtest.txt'\n",
    "    TEST_LABELS = 'ytest.txt'\n",
    "    VALIDATION_SIZE = 0\n",
    "    train_images = extract_images(TRAIN_IMAGES,L)\n",
    "    train_labels = extract_labels(nlabels,TRAIN_LABELS)\n",
    "    test_images = extract_images(TEST_IMAGES,L)\n",
    "    test_labels = extract_labels(nlabels,TEST_LABELS)\n",
    "    data_sets.train = DataSet(train_images, train_labels)\n",
    "    data_sets.test = DataSet(test_images, test_labels)\n",
    "    return data_sets\n",
    "\n",
    "def evalute_model(x,y,y_model):\n",
    "    acc = np.zeros((Ntemp))\n",
    "    output = np.zeros((Ntemp,2))\n",
    "\n",
    "    # Average output of neural net over the test set\n",
    "    ii=0\n",
    "    for i in range(Ntemp):\n",
    "        av=0.0\n",
    "        for j in range(samples_per_T):\n",
    "            test_image = data.test.images[ii,:].reshape((1,L*L))\n",
    "            test_label = np.asarray([1],data.test.labels[ii])\n",
    "            batch_valid=(test_image,test_label)  \n",
    "            res=sess.run(y_model,feed_dict={x: batch_valid[0], y: batch_valid[1]})\n",
    "            av=av+res \n",
    "            ii=ii+1 \n",
    "        av=av/samples_per_T\n",
    "        output[i,0] = av[0,0]\n",
    "        output[i,1] = av[0,1]\n",
    "\n",
    "    #Average accuracy vs temperature over the test set\n",
    "    for ii in range(Ntemp):\n",
    "        test_images = data.test.images[ii*samples_per_T:ii*samples_per_T+samples_per_T,:].reshape(samples_per_T,L*L)\n",
    "        test_labels = np.asarray(data.test.labels[ii*samples_per_T:ii*samples_per_T+samples_per_T])\n",
    "        batch_valid = (test_images,test_labels)\n",
    "        test_accuracy = sess.run(accuracy,feed_dict={\n",
    "            x:batch_valid[0], y: batch_valid[1]}) \n",
    "        acc[ii] = test_accuracy\n",
    "\n",
    "    return acc,output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature list at which the training/test sets were generated\n",
    "tlist=[1.0000000000000000,1.0634592657106510,1.1269185314213019,1.1903777971319529,1.2538370628426039,1.3172963285532548,1.3807555942639058,1.4442148599745568,1.5076741256852078,1.5711333913958587,1.6345926571065097,1.6980519228171607,1.7615111885278116,1.8249704542384626,1.8884297199491136,1.9518889856597645,2.0153482513704155,2.0788075170810667,2.1422667827917179,2.2057260485023691,2.3326445799236715,2.3961038456343227,2.4595631113449739,2.5230223770556250,2.5864816427662762,2.6499409084769274,2.7134001741875786,2.7768594398982298,2.8403187056088810,2.9037779713195322,2.9672372370301834,3.0306965027408346,3.0941557684514858,3.1576150341621370,3.2210742998727881,3.2845335655834393,3.3479928312940905,3.4114520970047417,3.4749113627153929,3.5383706284260401]\n",
    "\n",
    "# Description of the input data \n",
    "Ntemp=40           # number of different temperatures used in the training and testing data\n",
    "samples_per_T=250  # number of samples per temperature value in the testing set\n",
    "Nord=20            # number of temperatures in the ordered phase\n",
    "\n",
    "# Model Parameters\n",
    "L=30   # linear size of the lattice\n",
    "K=2    # number of phases\n",
    "N=L*L  # number of spins\n",
    "\n",
    "# Loading the data\n",
    "tar = tarfile.open('CompPhys2-machinelearning2_DATA.tar.gz', \"r:gz\")\n",
    "tar.extractall()\n",
    "tar.close() \n",
    "data = read_data_sets(K,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "L2 = 0.0                  # regularization parameter\n",
    "batch_size = 50           # batch size\n",
    "epochs = 4000             # training steps\n",
    "nh = 1                    # number of hidden neurons\n",
    "learning_rate = 0.1       # learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "W = tf.Variable(tf.truncated_normal([ N, nh], mean=0.0,stddev=0.1, dtype=tf.float32))\n",
    "W1 = tf.Variable(tf.truncated_normal([ nh, K], mean=0.0,stddev=0.1, dtype=tf.float32))\n",
    "b = tf.Variable(0.1*tf.ones([nh]), dtype=tf.float32)\n",
    "b1 = tf.Variable(0.1*tf.ones([K]), dtype=tf.float32)\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, N])\n",
    "y = tf.placeholder(tf.int32,[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# Define here the forward pass\n",
    "# Use sigmoid neurons also in the last layer (we only have two classes here)\n",
    "\n",
    "def forward_pass(x,w,b):\n",
    "    #.....\n",
    "    \n",
    "# This is the output of the model\n",
    "y_model= #......\n",
    "\n",
    "\n",
    "# Cost function     \n",
    "cost = #.....         +(L2)*(tf.nn.l2_loss(W)+tf.nn.l2_loss(W1))\n",
    "\n",
    "# Optimizer\n",
    "optimizer= tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(cost)\n",
    "\n",
    "# Evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(y_model,1), tf.argmax(tf.one_hot(y,depth=K),1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_init=sess.run(W)\n",
    "b_init=sess.run(b)\n",
    "\n",
    "for i in range(epochs+1):\n",
    "    batch = data.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "    if i%250 == 0:\n",
    "        train_accuracy = sess.run(accuracy,feed_dict={\n",
    "            x:batch[0], y: batch[1]})\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={\n",
    "            x: data.test.images, y: data.test.labels})\n",
    "        loss = sess.run(cost,feed_dict={x: batch[0], y: batch[1]})\n",
    "        print(\"Epoch = %d \\t loss %f \\t Trainset Accuracy = %.4f \\t Testset Accuracy = %.4f\" % (i, loss,train_accuracy,test_accuracy))\n",
    "        W_opt=sess.run(W)\n",
    "        b_opt=sess.run(b)\n",
    "        acc,output=evalute_model(x,y,y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (9.0, 9.0)\n",
    "plt.subplot(211)\n",
    "c = plt.cm.spectral((1)/4.,1)\n",
    "plt.plot(tlist,output[:,0],marker='D',markersize=5,color=c,linewidth=1,label='FM neuron')\n",
    "c = plt.cm.spectral((2)/4.,1)\n",
    "plt.plot(tlist,output[:,1],marker='s',markersize=5,color=c,linewidth=1,label='PM neuron')\n",
    "leg = plt.legend(loc='right',numpoints=1,markerscale=1.0,fontsize=15,labelspacing=0.1)\n",
    "plt.ylabel('Average output layer', fontsize=15)\n",
    "plt.xlabel(r'$T$', fontsize=15,labelpad=0)\n",
    "plt.xlim([1,3.5383706284260401])\n",
    "plt.ylim([0,1])\n",
    "x_tc=[2.26918,2.26918]\n",
    "y_tc=[0,1]\n",
    "plt.plot(x_tc, y_tc,color='#FFA500',linewidth=2)\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "c = 'r'\n",
    "plt.plot(tlist,acc,marker='*',markersize=5,color=c,linewidth=1)\n",
    "plt.ylabel('Average accuracy', fontsize=15)\n",
    "plt.xlabel(r'$T$', fontsize=15,labelpad=0)\n",
    "plt.xlim([1,3.5383706284260401])\n",
    "plt.ylim([0.6,1])\n",
    "\n",
    "\n",
    "x_tc=[2.26918,2.26918]\n",
    "y_tc=[0.6,1]\n",
    "plt.plot(x_tc, y_tc,color='#FFA500',linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "magnetizations = sess.run(2*tf.reduce_mean(data.test.images,1)-1)\n",
    "activations = sess.run(tf.matmul(x,W_opt)+b_opt,feed_dict={x:data.test.images})\n",
    "\n",
    "c = plt.cm.spectral((1)/4.,1)\n",
    "plt.plot(magnetizations,activations[:,0],marker='D',markersize=0.5,linewidth=0.0,color=c)\n",
    "c = plt.cm.spectral((2)/4.,1)\n",
    "plt.plot(magnetizations,activations[:,1],marker='D',markersize=0.5,linewidth=0.0,color=c)\n",
    "c = 'k'\n",
    "plt.plot(magnetizations,activations[:,2],marker='D',markersize=0.5,linewidth=0.0,color=c)\n",
    "plt.ylabel('$Wx+b$', fontsize=15)\n",
    "plt.xlabel(r'$m(x)$', fontsize=15,labelpad=0)\n",
    "plt.xlim([-1,1])\n",
    "#plt.ylim([0,1])\n",
    "x_grid=[0,0]\n",
    "y_grid=[np.min(activations),np.max(activations)]\n",
    "plt.plot(x_grid, y_grid,color='r',linewidth=1)\n",
    "y_grid=[0,0]\n",
    "x_grid=[-1,1]\n",
    "plt.plot(x_grid, y_grid,color='r',linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
